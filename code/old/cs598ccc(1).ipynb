{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Azure open AI Service\n",
    "\n"
   ],
   "metadata": {
    "id": "7qmkGDl8tQhj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set up the env\n",
    "* install the required packages\n",
    "* create .env file,\n",
    "  ```\n",
    "  OPENAI_API_KEY=\"xxx\"\n",
    "  ```\n",
    "* upload the file to /content folder\n",
    "  * need to upload everytime when start a new session\n"
   ],
   "metadata": {
    "id": "e7xn-rL-5VTL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# work around to wrap the text from response\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# autowrap the output\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ],
   "metadata": {
    "id": "-IfH0k7pyYqj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "proxifier_log_fie = \"data/summary/logs/Proxifier.txt\"\n",
    "\n",
    "SUMMARY = 'summary'\n",
    "LOG = 'log'\n",
    "def get_record_type(key):\n",
    "  if key.startswith(\"#summary:#\"):\n",
    "    return SUMMARY\n",
    "  else:\n",
    "    return LOG\n",
    "\n",
    "def load_data(file):\n",
    "  data_log = {}\n",
    "  data_summary = []\n",
    "  current_key = None\n",
    "  lines = []\n",
    "  record_type = LOG\n",
    "\n",
    "  with open(file, 'r') as file:\n",
    "    for line in file:\n",
    "      line = line.strip()\n",
    "      if not line:\n",
    "        continue\n",
    "\n",
    "      if line.startswith(\"#\"):\n",
    "        if current_key is not None:\n",
    "          if get_record_type(current_key) == SUMMARY:\n",
    "            data_summary.append(lines)\n",
    "          else:\n",
    "            data_log[current_key.replace(\"#\", \"\")] = lines\n",
    "\n",
    "        current_key = line\n",
    "        lines = []\n",
    "      else:\n",
    "        lines.append(line)\n",
    "\n",
    "    if current_key is not None:\n",
    "      data_summary.append(lines)\n",
    "  return data_log, data_summary\n",
    "\n",
    "p_data, p_summary = load_data(proxifier_log_fie)\n",
    "print(len(p_data))\n",
    "print( ', '.join(p_data.keys()))\n",
    "print('\\n'.join(p_data['1']))\n",
    "print(p_summary[0])\n",
    "print(len(p_data['2']))\n",
    "print(len(p_summary))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-kVuAgwGnID",
    "outputId": "b4d586ca-f866-4f50-9ea4-cc4ecf52b9b2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 403 bytes sent , 426 bytes received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1036 bytes ( 1.01 KB ) sent , 34151 bytes ( 33.3 KB ) received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1040 bytes ( 1.01 KB ) sent , 15872 bytes ( 15.5 KB ) received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1066 bytes ( 1.04 KB ) sent , 1782 bytes ( 1.74 KB ) received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1060 bytes ( 1.03 KB ) sent , 1633 bytes ( 1.59 KB ) received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1091 bytes ( 1.06 KB ) sent , 367 bytes received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1097 bytes ( 1.07 KB ) sent , 366 bytes received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1052 bytes ( 1.02 KB ) sent , 8362 bytes ( 8.16 KB ) received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 1124 bytes ( 1.09 KB ) sent , 529 bytes received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 0 bytes sent , 0 bytes received , lifetime 00 : 01\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "['open through proxy; bytes sent; bytes received; close;']\n",
      "20\n",
      "100\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('Proxifier sample log:\\n')\n",
    "print('\\n'.join(p_data['2']))\n",
    "print(f'\\nProxifier sample summary:\\n {p_summary[1][0]}')\n",
    "\n",
    "print('\\n\\nZookeeper sample log:\\n')\n",
    "print('\\n'.join(z_data['2']))\n",
    "print(f'\\nZookeeper sample summary:\\n {z_summary[1][0]}')"
   ],
   "metadata": {
    "id": "z5n2hK0Yrsko",
    "outputId": "23d9d590-7e94-417f-eea9-1066170ab754",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proxifier sample log:\n",
      "\n",
      "- tcpconn.tencent.com : 80 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- tcpconn.tencent.com : 443 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- tcpconn.tencent.com : 80 close , 0 bytes sent , 0 bytes received , lifetime <1 sec\n",
      "- tcpconn.tencent.com : 443 close , 0 bytes sent , 0 bytes received , lifetime <1 sec\n",
      "- tcpconn5.tencent.com : 80 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- tcpconn5.tencent.com : 80 close , 0 bytes sent , 0 bytes received , lifetime <1 sec\n",
      "- tcpconn5.tencent.com : 443 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- tcpconn5.tencent.com : 443 close , 0 bytes sent , 0 bytes received , lifetime <1 sec\n",
      "- 183.60.48.250 : 443 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 close , 639 bytes sent , 339 bytes received , lifetime <1 sec\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- proxy.cse.cuhk.edu.hk : 5070 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- tcpconn4.tencent.com : 80 error : Could not connect through proxy proxy.cse.cuhk.edu.hk : 5070 - Proxy closed the connection unexpectedly.\n",
      "- tcpconn4.tencent.com : 443 error : Could not connect through proxy proxy.cse.cuhk.edu.hk : 5070 - Proxy closed the connection unexpectedly.\n",
      "- cgi.qqweb.qq.com : 80 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- cgi.qqweb.qq.com : 80 close , 477 bytes sent , 448 bytes received , lifetime <1 sec\n",
      "- cgi.qqweb.qq.com : 80 open through proxy proxy.cse.cuhk.edu.hk : 5070 HTTPS\n",
      "- cgi.qqweb.qq.com : 80 close , 477 bytes sent , 448 bytes received , lifetime <1 sec\n",
      "\n",
      "Proxifier sample summary:\n",
      " open through proxy; bytes sent; bytes received; close; Could not connect through proxy; Proxy closed the connection;\n",
      "\n",
      "\n",
      "Zookeeper sample log:\n",
      "\n",
      "INFO Accepted socket connection from /10.10.34.11 : 49242\n",
      "WARN Connection request from old client /10.10.34.11 : 49242 ; will be dropped if server is in r-o mode\n",
      "INFO Client attempting to establish new session at /10.10.34.11 : 49242\n",
      "INFO Accepted socket connection from /10.10.34.11 : 49244\n",
      "WARN Connection request from old client /10.10.34.11 : 49244 ; will be dropped if server is in r-o mode\n",
      "INFO Client attempting to establish new session at /10.10.34.11 : 49244\n",
      "INFO Established session 0x14ed93111f20037 with negotiated timeout 10000 for client /10.10.34.11 : 49242\n",
      "INFO Established session 0x14ed93111f20038 with negotiated timeout 10000 for client /10.10.34.11 : 49244\n",
      "INFO Accepted socket connection from /10.10.34.13 : 37196\n",
      "WARN Connection request from old client /10.10.34.13 : 37196 ; will be dropped if server is in r-o mode\n",
      "INFO Client attempting to establish new session at /10.10.34.13 : 37196\n",
      "INFO Established session 0x14ed93111f20039 with negotiated timeout 10000 for client /10.10.34.13 : 37196\n",
      "INFO Accepted socket connection from /10.10.34.12 : 45605\n",
      "WARN Connection request from old client /10.10.34.12 : 45605 ; will be dropped if server is in r-o mode\n",
      "INFO Client attempting to establish new session at /10.10.34.12 : 45605\n",
      "INFO Established session 0x14ed93111f2003a with negotiated timeout 10000 for client /10.10.34.12 : 45605\n",
      "INFO Accepted socket connection from /10.10.34.13 : 37199\n",
      "WARN Connection request from old client /10.10.34.13 : 37199 ; will be dropped if server is in r-o mode\n",
      "INFO Client attempting to establish new session at /10.10.34.13 : 37199\n",
      "INFO Established session 0x14ed93111f2003b with negotiated timeout 10000 for client /10.10.34.13 : 37199\n",
      "\n",
      "Zookeeper sample summary:\n",
      " Accepted socket connection;Connection request will be dropped; Client attempting to establish new session; Established session timeout;\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "import time\n",
    "dotenv.load_dotenv('./.env')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = \"https://aiops23.openai.azure.com/\",\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "  api_version=\"2023-09-15-preview\"\n",
    ")\n",
    "\n",
    "def open_ai_summary(model, input):\n",
    "  text = '\\n'.join(input)\n",
    "\n",
    "  template = f\"\"\"\n",
    "  sure, I can create a template for summary as the following:\n",
    "  opening port [Port Number], transmitting variable data ('[Transmitted Data]'), receiving ('[Received Data]') with average [Average Speed] MB/s, variance [Variance Speed] MB/s, finally closing the port.\"\n",
    "  \"\"\"\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a networking specialist and understand how proxy works\"},\n",
    "        {\"role\": \"user\", \"content\": \"Help me to create a concise summary less than 20 words, the output is a josn summary with the following keys: summary, throughput, anormly\"},\n",
    "        {\"role\": \"assistant\", \"content\": template},\n",
    "        {\"role\": \"user\", \"content\":  text},\n",
    "    ],\n",
    "    temperature=0.3,\n",
    "    max_tokens=250,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    "  )\n",
    "\n",
    "  print(response.choices[0].message.content)\n",
    "\n",
    "  return response.choices[0].message.content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DekEL3YctPqC",
    "outputId": "63870afd-d106-4a86-b249-03cb3f40b294"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "engines = ['gpt3', 'gpt4']\n",
    "\n",
    "results = pd.DataFrame(columns=['ref', 'gen3', 'gen4', 'log'])\n",
    "\n",
    "for index, ref in enumerate(p_summary):\n",
    "  # print(f\"Key: {index}, Value: {input}\")\n",
    "  if index > 10:\n",
    "    continue\n",
    "  new_row = [ref]\n",
    "  input = p_data[str(index+1)]\n",
    "  for engine in engines:\n",
    "    summary = open_ai_summary(engine, input)\n",
    "    print(summary)\n",
    "    new_row.append(summary)\n",
    "    time.sleep(10)\n",
    "\n",
    "  new_row.append('\\n'.join(input))\n",
    "  new_row = pd.DataFrame([new_row], columns=results.columns)\n",
    "  results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "results.to_csv('openai_proxifier.csv', index=False)"
   ],
   "metadata": {
    "id": "1MVYZIuBlf5L",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "outputId": "08825493-56d3-4afb-dc13-662dd18245d3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-59bbb4abff52>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mengines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'gpt3'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'gpt4'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ref'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'gen3'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'gen4'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'log'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mref\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp_summary\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "zookeeper_log_fie = \"/content/code-and-datasets/data/summary/logs/Zookeeper.txt\"\n",
    "z_data, z_summary = load_data(zookeeper_log_fie)\n",
    "print(len(z_data))\n",
    "print( ', '.join(z_data.keys()))\n",
    "print('\\n'.join(z_data['1']))\n",
    "print(z_summary[0])\n",
    "print(len(z_data['2']))\n",
    "print(len(z_summary))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9e1rG5bDKkz",
    "outputId": "8c240b0e-be5c-4bbc-ae4e-516de8966a72"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100\n",
      "WARN Send worker leaving thread\n",
      "INFO Received connection request /10.10.34.11 : 45328\n",
      "WARN Connection broken for id 188978561024 , my id = 1 , error =\n",
      "WARN Interrupting SendWorker\n",
      "WARN Interrupted while waiting for message on queue\n",
      "WARN Send worker leaving thread\n",
      "INFO Received connection request /10.10.34.11 : 45329\n",
      "WARN Connection broken for id 188978561024 , my id = 1 , error =\n",
      "WARN Interrupting SendWorker\n",
      "WARN Interrupted while waiting for message on queue\n",
      "WARN Send worker leaving thread\n",
      "INFO Received connection request /10.10.34.11 : 45336\n",
      "INFO Received connection request /10.10.34.11 : 45338\n",
      "WARN Interrupted while waiting for message on queue\n",
      "WARN Connection broken for id 188978561024 , my id = 1 , error =\n",
      "WARN Interrupting SendWorker\n",
      "WARN Send worker leaving thread\n",
      "WARN Connection broken for id 188978561024 , my id = 1 , error =\n",
      "WARN Interrupting SendWorker\n",
      "WARN Interrupted while waiting for message on queue\n",
      "['Send worker leaving thread; Received connection request; Connection broken; Interrupted; Interrupting SendWorker;']\n",
      "20\n",
      "101\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def open_ai_zk_summary(model, input, train):\n",
    "  text = '\\n'.join(input)\n",
    "  # print(input)\n",
    "\n",
    "  prompts=[]\n",
    "  prompts.append({\"role\": \"system\", \"content\": \"You are a zookeeper specialist\"})\n",
    "  prompts.append({\"role\": \"user\", \"content\": \"Help me to create a concise summary less than 20 words, \\\n",
    "  the output is a josn summary with the following keys: summary, anormly\"})\n",
    "  prompts.append({\"role\": \"assistant\", \"content\": \"yes, I can do it.\"})\n",
    "\n",
    "  logs, summary = train[0], train[1]\n",
    "\n",
    "  for i in range(len(train[0])):\n",
    "    userContent = '\\n'.join(logs[i])\n",
    "    assistantContent = summary[i][0]\n",
    "    prompts.append({\"role\": \"user\", \"content\": f\"\"\"create a summary for: {userContent}\"\"\"})\n",
    "    # data = f\"\"\"\"summary\": {assistantContent}\"\"\"\n",
    "    prompts.append({\"role\": \"assistant\", \"content\": assistantContent})\n",
    "\n",
    "  prompts.append({\"role\": \"user\", \"content\": f\"create a summary for: {text}\"})\n",
    "\n",
    "  # for i in range(len(prompts)):\n",
    "  #   print(prompts[i])\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=prompts,\n",
    "    temperature=0.3,\n",
    "    max_tokens=250,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    "  )\n",
    "\n",
    "  print(f'response:{response.choices[0].message.content}')\n",
    "\n",
    "  return response.choices[0].message.content"
   ],
   "metadata": {
    "id": "1v4JOHjsnxa_",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "outputId": "4dbc6519-5928-4d9f-9fd1-3cd89eca5c0e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#  openai migrate\n",
    "\n",
    "engines = ['gpt3', 'gpt4']\n",
    "\n",
    "results = pd.DataFrame(columns=['ref', 'gen3', 'gen4', 'log'])\n",
    "\n",
    "# use first 10 rows as training set\n",
    "trains = ([],[])\n",
    "for i in range(5):\n",
    "  trains[0].append(z_data[str(index+1)])\n",
    "  trains[1].append(z_summary[i][0])\n",
    "\n",
    "print(len(trains[0][0]))\n",
    "print(len(trains[1][0]))\n",
    "\n",
    "for index, ref in enumerate(z_summary):\n",
    "  # print(f\"Key: {index}, Value: {input}\")\n",
    "  if index < 10 or index > 20:\n",
    "    continue\n",
    "  new_row = [ref]\n",
    "  input = z_data[str(index+1)]\n",
    "  for engine in engines:\n",
    "    summary = open_ai_zk_summary(engine, input, trains)\n",
    "    # print(summary)\n",
    "    new_row.append(summary)\n",
    "    time.sleep(10)\n",
    "\n",
    "  new_row.append('\\n'.join(input))\n",
    "  new_row = pd.DataFrame([new_row], columns=results.columns)\n",
    "  results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "results.to_csv('openai_zookeeper.csv', index=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "pRc9XjkR9JmH",
    "outputId": "40b0bed3-4cc3-4ba6-83a4-67ba9e8bcac7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20\n",
      "113\n",
      "response:{\n",
      "  \"summary\": \"Processed session terminations and expirations, accepted socket connection, caught end of stream exception, and closed socket connection.\",\n",
      "  \"anomaly\": \"None\"\n",
      "}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-739f38eb68e0>\u001B[0m in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;31m# print(summary)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0mnew_row\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m     \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m   \u001B[0mnew_row\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'\\n'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ]
}
