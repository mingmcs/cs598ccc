{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "9a96b31e0afb4820b825aa947110b0c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3e1a2d23b5f452da817c26af2a39d26",
       "IPY_MODEL_9dbd1a27d8434094be76033bb74d5785",
       "IPY_MODEL_7722b0309ef64346b238dfc535f75fdf"
      ],
      "layout": "IPY_MODEL_d2a9d35183804ef2952a63635b19d3d6"
     }
    },
    "f3e1a2d23b5f452da817c26af2a39d26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e80600277118404f8261e5469ed1576d",
      "placeholder": "​",
      "style": "IPY_MODEL_20ed6139292641ed9be2072d21e25be1",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "9dbd1a27d8434094be76033bb74d5785": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e8b97d2fe5a498da38589f769b73668",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6cf666b931a4b958022ab7aa3f32fb9",
      "value": 28
     }
    },
    "7722b0309ef64346b238dfc535f75fdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c1571adaf124a5ba1059b316f7627d5",
      "placeholder": "​",
      "style": "IPY_MODEL_09ac1fb205584f5fab1a9db9c0c1af3d",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.18kB/s]"
     }
    },
    "d2a9d35183804ef2952a63635b19d3d6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e80600277118404f8261e5469ed1576d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20ed6139292641ed9be2072d21e25be1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e8b97d2fe5a498da38589f769b73668": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6cf666b931a4b958022ab7aa3f32fb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c1571adaf124a5ba1059b316f7627d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09ac1fb205584f5fab1a9db9c0c1af3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4368d74ceab44db890d7ff95c4b4f51e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba1fa43b35404c28a2350a6b7cd0b9ad",
       "IPY_MODEL_edfce29478f24e758e2e5cc5d6d0f458",
       "IPY_MODEL_568481a9be9b4c138bc35becdb44a74a"
      ],
      "layout": "IPY_MODEL_11042d25e05d458bb5b8ee9ca9ed982d"
     }
    },
    "ba1fa43b35404c28a2350a6b7cd0b9ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a40304d26da4518a51291df1312be54",
      "placeholder": "​",
      "style": "IPY_MODEL_f218eae7109340e9add0c22f3cd0ea6a",
      "value": "config.json: 100%"
     }
    },
    "edfce29478f24e758e2e5cc5d6d0f458": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38bf29c35c4e4bdf84e39b463c1d917b",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c318af3b017c44f7b6fa0e2799895eb4",
      "value": 570
     }
    },
    "568481a9be9b4c138bc35becdb44a74a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18c2878290d74a729371760532383de6",
      "placeholder": "​",
      "style": "IPY_MODEL_0e7b9c99860e46cf8104551907a889a0",
      "value": " 570/570 [00:00&lt;00:00, 23.6kB/s]"
     }
    },
    "11042d25e05d458bb5b8ee9ca9ed982d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a40304d26da4518a51291df1312be54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f218eae7109340e9add0c22f3cd0ea6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38bf29c35c4e4bdf84e39b463c1d917b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c318af3b017c44f7b6fa0e2799895eb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "18c2878290d74a729371760532383de6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e7b9c99860e46cf8104551907a889a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bf53b9184454bccae3cd157a48ed813": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a5946505a1d4e5caa0f41fb71e7c5f4",
       "IPY_MODEL_3d2ee7766f6c4b6185e55271adaeb1d3",
       "IPY_MODEL_aef7d15f24134f1ab98af824d2d05260"
      ],
      "layout": "IPY_MODEL_4c6b609be3b2436e8079ccc76c2cd150"
     }
    },
    "8a5946505a1d4e5caa0f41fb71e7c5f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6c9dbb0ab8e416baaede26741648d16",
      "placeholder": "​",
      "style": "IPY_MODEL_a0c3433840b24d91af8ab1e9b2d37a7f",
      "value": "vocab.txt: 100%"
     }
    },
    "3d2ee7766f6c4b6185e55271adaeb1d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05c6eee39b564e26988400d5ac4d7b53",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a64e07aa871b48dbb1ac0d27cc2362dc",
      "value": 231508
     }
    },
    "aef7d15f24134f1ab98af824d2d05260": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_367aa752cb264d04a285502b2e06dece",
      "placeholder": "​",
      "style": "IPY_MODEL_802d4bc1af424da4b3bf18bc839955fb",
      "value": " 232k/232k [00:00&lt;00:00, 1.84MB/s]"
     }
    },
    "4c6b609be3b2436e8079ccc76c2cd150": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6c9dbb0ab8e416baaede26741648d16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0c3433840b24d91af8ab1e9b2d37a7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05c6eee39b564e26988400d5ac4d7b53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a64e07aa871b48dbb1ac0d27cc2362dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "367aa752cb264d04a285502b2e06dece": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "802d4bc1af424da4b3bf18bc839955fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "269f674830d840389e135f12e78ef105": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8dcbfd10d4034869afd42d1ae2dca34e",
       "IPY_MODEL_2587ccfb8ad74d789fa6bf5c66fed1aa",
       "IPY_MODEL_e3a4152d63504a5082c110a5e3b85163"
      ],
      "layout": "IPY_MODEL_6108d3a5a55c474594785f944419c04e"
     }
    },
    "8dcbfd10d4034869afd42d1ae2dca34e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53e7694eb9d8409a90037c5f11487a17",
      "placeholder": "​",
      "style": "IPY_MODEL_b233a6632a7a452f8dd1eb89fb8660cd",
      "value": "tokenizer.json: 100%"
     }
    },
    "2587ccfb8ad74d789fa6bf5c66fed1aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04ded8cab7d24448ad9c9ed7c8356b1f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bdcc324b02d84ff0bfe8d3f5286fb231",
      "value": 466062
     }
    },
    "e3a4152d63504a5082c110a5e3b85163": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0461696da9f94bc6aa01fce358a91f61",
      "placeholder": "​",
      "style": "IPY_MODEL_5d0f67a5d7dd41e6abe8ae291cc3cfd6",
      "value": " 466k/466k [00:00&lt;00:00, 3.74MB/s]"
     }
    },
    "6108d3a5a55c474594785f944419c04e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53e7694eb9d8409a90037c5f11487a17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b233a6632a7a452f8dd1eb89fb8660cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04ded8cab7d24448ad9c9ed7c8356b1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdcc324b02d84ff0bfe8d3f5286fb231": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0461696da9f94bc6aa01fce358a91f61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d0f67a5d7dd41e6abe8ae291cc3cfd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac90b521ccf14528866020de05c0263b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b13a3c180a4749a29d5a40a0d9d3f934",
       "IPY_MODEL_df7e6ed6878c4317b39ffd0109e44411",
       "IPY_MODEL_ff66241e2a3f414c8434c2f847b5f1c8"
      ],
      "layout": "IPY_MODEL_44dacb118e8e46128f19007c7bcc5d3c"
     }
    },
    "b13a3c180a4749a29d5a40a0d9d3f934": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31b3b433d52744a795d5f6e75ffe8c82",
      "placeholder": "​",
      "style": "IPY_MODEL_1dbff931094c48a8921b4671bb2955c1",
      "value": "model.safetensors: 100%"
     }
    },
    "df7e6ed6878c4317b39ffd0109e44411": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adfe4cad78404860bbd99ee158d7b9e8",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f88f80b9b5e440b585676c800759f3d6",
      "value": 440449768
     }
    },
    "ff66241e2a3f414c8434c2f847b5f1c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ce4c9ae6dc449a4b8a6cd80a934438f",
      "placeholder": "​",
      "style": "IPY_MODEL_1d403f71be494c19af64d9563eba378e",
      "value": " 440M/440M [00:04&lt;00:00, 143MB/s]"
     }
    },
    "44dacb118e8e46128f19007c7bcc5d3c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31b3b433d52744a795d5f6e75ffe8c82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dbff931094c48a8921b4671bb2955c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "adfe4cad78404860bbd99ee158d7b9e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f88f80b9b5e440b585676c800759f3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ce4c9ae6dc449a4b8a6cd80a934438f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d403f71be494c19af64d9563eba378e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qBJqaXbHs4bN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3a0700f0-55b5-4d3c-da43-83c47a46c29e",
    "ExecuteTime": {
     "end_time": "2023-12-10T05:45:55.041626800Z",
     "start_time": "2023-12-10T05:45:55.004464900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "try:\n",
    "  nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "  nltk.download('punkt')\n",
    "  nltk.download('wordnet')\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from bert_score import BERTScorer, score\n",
    "from nubia_score import Nubia\n",
    "\n",
    "import toml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'useEmbeddings': False, 'openAiApiKey': '5f922fc571534517acc85c31d6af4bbf', 'dataPath': 'data/summary/logs/Zookeeper.txt', 'logsSourceApplication': 'Zookeeper', 'engines': ['gpt3', 'gpt4'], 'outputDir': 'out', 'outputFilename': 'zookeeper_without_embeddings', 'data': {'splitRandomState': 0, 'trainProportion': 0.75}, 'model': {'temperature': 0.3, 'maxTokens': 250, 'topP': 1, 'frequencyPenalty': 0, 'presencePenalty': 0}, 'embedding': {'useEmbeddings': False, 'model': 'text-embedding-ada-002', 'deployment': 'cs598', 'resourceEndpoint': 'https://openaics598.openai.azure.com', 'apiKey': '5309dd9cfd0e4e9cadd598ee91321fcf', 'openAiApiVersion': '2023-05-15', 'chunkSize': 16, 'openAiApiType': 'azure', 'redis': {'hostName': 'localhost', 'port': '6379', 'indexName': 'log_data', 'kDocs': 5}}}\n"
     ]
    }
   ],
   "source": [
    "with open('config.toml', 'r') as f:\n",
    "    config = toml.load(f)\n",
    "    print(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T05:45:56.881429Z",
     "start_time": "2023-12-10T05:45:56.850804400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lexical metrics:\n",
    "* BLEU Score\n",
    "  * Range from 0 to 1, Higher Is Better\n",
    "  * 0 indicates no similarity in between\n",
    "  * 1 indicates that is identical\n",
    "  * 0.4-0.6 is considered reasonable and indicates some level of similarity\n",
    "  * above 0.6 is considered quite good\n",
    "  \n",
    "* ROUGE Score\n",
    "  * Range from 0 to 1, Higher Is Better\n",
    "  * 0 indicates no similarity in between\n",
    "  * 1 indicates that is identical\n",
    "  * round 0.2-0.4 indicates some level of overlap\n",
    "  * above 0.4 is considered good\n",
    "\n",
    "* Meteor Score\n",
    "  * Range from 0 to 1, Higher Is Better\n",
    "  * 0 indicates no similarity in between\n",
    "  * 1 indicates that is identical\n",
    "  * 0.4-0.6 is considered reasonable and indicates some level of similarity\n",
    "  * above 0.6 is considered quite good"
   ],
   "metadata": {
    "id": "UIfOJNeJ918S"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def bleu_score(ref, gen):\n",
    "  smoother = SmoothingFunction()\n",
    "  return sentence_bleu([ref.split()], gen.split(), smoothing_function=smoother.method4)\n",
    "\n",
    "\n",
    "def rouge_score(ref, gen):\n",
    "  return rouge_scorer \\\n",
    "    .RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True) \\\n",
    "    .score(ref, gen)[\"rougeL\"] \\\n",
    "    .fmeasure\n",
    "\n",
    "\n",
    "def meteor_score(ref, gen):\n",
    "  return single_meteor_score(word_tokenize(ref), word_tokenize(gen))\n",
    "\n",
    "def bert_score(ref, gen):\n",
    "  p, r, f1 = BERTScorer(model_type='bert-base-uncased').score([gen], [ref])\n",
    "  return f1.item()\n",
    "\n",
    "def bleurt_score(ref, gen):\n",
    "  p, r, f1 = score([gen], [ref], lang=\"en\", verbose=False)\n",
    "  return f1.item()\n",
    "\n",
    "def nubia_score(ref, gen):\n",
    "  return Nubia().score(ref, gen, verbose=False, get_features=True)['nubia_score']\n",
    "\n",
    "def plot_results(scores, title):\n",
    "  df_long = scores.melt(var_name='Metrics', value_name='Value')\n",
    "  plt.figure(figsize=(5, 3))\n",
    "  sns.boxplot(x='Metrics', y='Value', data=df_long, width=0.5, showfliers=False)\n",
    "  sns.stripplot(x='Metrics', y='Value', data=df_long, jitter=True, color='black', alpha=0.5)\n",
    "\n",
    "  plt.axhline(0.2, color='red', linestyle='--', label=f'Threshold 1: {0.2}')\n",
    "  plt.axhline(0.4, color='green', linestyle='--', label=f'Threshold 2: {0.4}')\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "ZD4ZKZzPaw8N",
    "ExecuteTime": {
     "end_time": "2023-12-10T05:46:00.216849700Z",
     "start_time": "2023-12-10T05:46:00.183715500Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Semantic metrics:\n",
    "* BERTScore\n",
    "  * Range from 0 to 1, Higher Is Better\n",
    "  * 0 indicates no similarity in between\n",
    "  * 1 indicates that is identical\n",
    "  * 0.6-0.7 is considered good and indicates that the generated text is similar to the reference in terms of both vocabulary and context.\n",
    "  * above 0.6 is considered quite good\n",
    "  \n",
    "* BLEURT\n",
    "  * typically range from negative to positive\n",
    "  * A positive BLEURT score indicates that the generated text is considered better than randomly generated text. The higher the positive score, the better the quality.\n",
    "  * A negative BLEURT score suggests that the generated text is worse than randomly generated text. The lower the negative score, the worse the quality.\n",
    "  * A BLEURT score near zero implies that the quality of the generated text is neither better nor worse than randomly generated text.\n",
    "\n",
    "* NUBIA\n",
    "  * Range from 0 to 1, Higher Is Better\n",
    "  * how good of a substitute/replacement the candidate sentence is for the reference sentence.\n",
    "\n"
   ],
   "metadata": {
    "id": "HKRQ0kXQDhcj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def process_dataset(file):\n",
    "  df = pd.read_csv(file)\n",
    "\n",
    "  refs = [ref.replace(\"['\", \"\").replace(\"']\", \"\") for ref in df[\"ref\"]]\n",
    "  df[\"ref\"] = refs\n",
    "  \n",
    "  bleu_scores = []\n",
    "  rouge_scores = []\n",
    "  meteor_scores = []\n",
    "  bert_scores = []\n",
    "  bleurt_scores = []\n",
    "  nubia_scores = []\n",
    "  for summary, ref_log in tqdm(list(zip(refs, df[\"log\"]))):\n",
    "    bleu_scores.append(bleu_score(ref_log, summary))\n",
    "    rouge_scores.append(rouge_score(ref_log, summary))\n",
    "    meteor_scores.append(meteor_score(ref_log, summary))\n",
    "    bert_scores.append(bert_score(ref_log, summary))\n",
    "    bleurt_scores.append(bleurt_score(ref_log, summary))\n",
    "    nubia_scores.append(nubia_score(ref_log, summary))\n",
    "    \n",
    "  df[f\"ref BLEU\"] = bleu_scores\n",
    "  df[f\"ref ROUGE\"] = rouge_scores\n",
    "  df[f\"ref METEOR\"] = meteor_scores\n",
    "  df[f\"ref BERT\"] = bert_scores\n",
    "  df[f\"ref BLEURT\"] = bleurt_scores\n",
    "  df[f\"ref NUBIA\"] = nubia_scores\n",
    "  \n",
    "  for engine in config[\"engines\"]:\n",
    "    summaries = df[f\"{engine} summary\"]\n",
    "    ref_summaries = df[\"ref\"]\n",
    "    ref_logs = df[\"log\"]\n",
    "    \n",
    "    bleu_scores = []\n",
    "    rouge_scores = []\n",
    "    meteor_scores = []\n",
    "    bert_scores = []\n",
    "    bleurt_scores = []\n",
    "    nubia_scores = []\n",
    "    for summary, ref_summary, ref_log in tqdm(list(zip(summaries, ref_summaries, ref_logs))):\n",
    "      bleu_scores.append(bleu_score(ref_log, summary))\n",
    "      rouge_scores.append(rouge_score(ref_log, summary))\n",
    "      meteor_scores.append(meteor_score(ref_log, summary))\n",
    "      bert_scores.append(bert_score(ref_log, summary))\n",
    "      bleurt_scores.append(bleurt_score(ref_log, summary))\n",
    "      nubia_scores.append(nubia_score(ref_log, summary))\n",
    "        \n",
    "    df[f\"{engine} BLEU\"] = bleu_scores\n",
    "    df[f\"{engine} ROUGE\"] = rouge_scores\n",
    "    df[f\"{engine} METEOR\"] = meteor_scores\n",
    "    df[f\"{engine} BERT\"] = bert_scores\n",
    "    df[f\"{engine} BLEURT\"] = bleurt_scores\n",
    "    df[f\"{engine} NUBIA\"] = nubia_scores\n",
    "  return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T07:40:30.297733500Z",
     "start_time": "2023-12-10T07:40:30.226584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2023-12-10 00:40:34 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:40:45 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:40:52 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:41:02 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:41:02 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:41:06 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:41:19 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:41:21 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:41:21 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:41:21 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:41:21 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:41:21 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/25 [01:05<26:12, 65.54s/it]2023-12-10 00:41:39 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:41:51 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:41:58 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:42:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:42:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:42:15 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:42:24 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:42:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:42:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:42:26 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:42:26 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:42:26 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/25 [02:08<24:26, 63.74s/it]2023-12-10 00:42:42 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:42:55 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:43:00 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:43:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:43:10 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:43:14 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:43:24 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:43:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:43:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:43:25 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:43:25 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:43:26 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 12%|█▏        | 3/25 [03:11<23:20, 63.65s/it]2023-12-10 00:43:45 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:44:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:44:06 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:44:15 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:44:16 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:44:20 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:44:29 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:44:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:44:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:44:30 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:44:30 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:44:31 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 16%|█▌        | 4/25 [04:13<22:01, 62.91s/it]2023-12-10 00:44:47 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:45:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:45:04 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:45:11 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:45:11 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:45:14 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:45:21 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:45:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:45:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:45:22 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:45:22 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:45:23 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 20%|██        | 5/25 [05:04<19:35, 58.79s/it]2023-12-10 00:45:38 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:45:45 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:45:49 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:45:56 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:45:56 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:45:58 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:46:05 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:46:06 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:46:06 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:46:07 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:46:07 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:46:07 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 24%|██▍       | 6/25 [05:45<16:39, 52.63s/it]2023-12-10 00:46:19 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:46:30 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:46:33 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:46:40 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:46:40 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:46:43 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:46:51 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:46:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:46:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:46:52 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:46:52 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:46:53 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 7/25 [06:35<15:33, 51.84s/it]2023-12-10 00:47:09 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:47:20 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:47:23 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:47:30 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:47:31 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:47:33 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:47:41 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:47:42 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:47:42 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:47:42 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:47:42 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:47:43 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 8/25 [07:26<14:34, 51.41s/it]2023-12-10 00:48:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:48:11 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:48:15 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:48:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:48:23 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:48:25 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:48:33 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:48:34 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:48:34 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:48:35 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:48:35 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:48:35 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 9/25 [08:18<13:45, 51.56s/it]2023-12-10 00:48:52 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:48:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:49:02 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:49:10 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:49:11 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:49:13 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:49:21 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:49:23 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:49:23 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:49:24 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:49:24 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:49:24 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 40%|████      | 10/25 [09:02<12:21, 49.44s/it]2023-12-10 00:49:36 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:49:47 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:49:50 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:49:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:49:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:50:01 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:50:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:50:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:50:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:50:10 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:50:10 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:50:10 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 44%|████▍     | 11/25 [09:50<11:25, 48.99s/it]2023-12-10 00:50:24 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:50:31 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:50:34 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:50:41 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:50:42 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:50:46 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:50:53 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:50:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:50:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:50:55 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:50:55 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:50:56 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 48%|████▊     | 12/25 [10:34<10:15, 47.32s/it]2023-12-10 00:51:08 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:51:18 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:51:21 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:51:28 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:51:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:51:31 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:51:38 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:51:39 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:51:39 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:51:39 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:51:39 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:51:40 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 52%|█████▏    | 13/25 [11:21<09:25, 47.16s/it]2023-12-10 00:51:55 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:52:04 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:52:08 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:52:15 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:52:15 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:52:18 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:52:24 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:52:28 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:52:28 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:52:28 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:52:28 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:52:29 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 14/25 [12:08<08:40, 47.34s/it]2023-12-10 00:52:42 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:52:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:52:56 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:53:03 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:53:03 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:53:05 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:53:12 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:53:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:53:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:53:14 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:53:14 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:53:15 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 60%|██████    | 15/25 [12:56<07:53, 47.31s/it]2023-12-10 00:53:30 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:53:38 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:53:41 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:53:48 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:53:49 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:53:51 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:53:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:53:59 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:53:59 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:54:00 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:54:00 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:54:00 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 16/25 [13:39<06:55, 46.17s/it]2023-12-10 00:54:13 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:54:22 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:54:25 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:54:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:54:33 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:54:36 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:54:43 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:54:46 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:54:46 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:54:46 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:54:46 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:54:47 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 17/25 [14:26<06:11, 46.42s/it]2023-12-10 00:55:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:55:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:55:12 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:55:20 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:55:20 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:55:23 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:55:30 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:55:31 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:55:31 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:55:32 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:55:32 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:55:32 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 18/25 [15:11<05:22, 46.04s/it]2023-12-10 00:55:45 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:55:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:55:56 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:56:03 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:56:04 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:56:06 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:56:14 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:56:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:56:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:56:15 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:56:15 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:56:16 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 76%|███████▌  | 19/25 [15:53<04:28, 44.83s/it]2023-12-10 00:56:27 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:56:37 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:56:40 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:56:48 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:56:48 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:56:51 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:56:59 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:57:00 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:57:00 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:57:00 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:57:00 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:57:01 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 80%|████████  | 20/25 [16:42<03:49, 45.86s/it]2023-12-10 00:57:16 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:57:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:57:29 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:57:36 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:57:37 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:57:39 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:57:46 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:57:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:57:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:57:48 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:57:48 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:57:48 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 21/25 [17:29<03:05, 46.26s/it]2023-12-10 00:58:03 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:58:14 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:58:17 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:58:24 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:58:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:58:28 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:58:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:58:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:58:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:58:37 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:58:37 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:58:37 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 22/25 [18:19<02:22, 47.43s/it]2023-12-10 00:58:53 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:59:02 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:59:05 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:59:12 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:59:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 00:59:15 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 00:59:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 00:59:24 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 00:59:24 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 00:59:24 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 00:59:24 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 00:59:25 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 23/25 [19:04<01:33, 46.78s/it]2023-12-10 00:59:38 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 00:59:48 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:59:52 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 00:59:59 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:00:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:00:02 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:00:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:00:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:00:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:00:11 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:00:11 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:00:11 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 24/25 [19:52<00:46, 46.99s/it]2023-12-10 01:00:26 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:00:35 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:00:39 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:00:46 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:00:46 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:00:49 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:00:56 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:00:58 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:00:58 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:00:58 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:00:58 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:00:59 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [20:39<00:00, 49.57s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]2023-12-10 01:01:13 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:01:21 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:01:25 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:01:31 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:01:33 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:01:35 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:01:42 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:01:43 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:01:43 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:01:44 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:01:44 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:01:44 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/25 [00:44<17:57, 44.90s/it]2023-12-10 01:01:58 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:02:04 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:02:08 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:02:15 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:02:16 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:02:18 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:02:25 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:02:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:02:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:02:28 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:02:28 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:02:31 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/25 [01:29<17:13, 44.92s/it]2023-12-10 01:02:43 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:02:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:02:56 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:03:02 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:03:03 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:03:05 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:03:12 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:03:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:03:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:03:14 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:03:14 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:03:14 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 12%|█▏        | 3/25 [02:16<16:47, 45.79s/it]2023-12-10 01:03:30 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:03:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:03:43 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:03:50 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:03:51 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:03:53 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:04:00 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:04:01 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:04:01 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:04:01 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:04:01 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:04:03 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 16%|█▌        | 4/25 [03:04<16:18, 46.59s/it]2023-12-10 01:04:17 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:04:28 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:04:31 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:04:38 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:04:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:04:41 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:04:48 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:04:49 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:04:49 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:04:50 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:04:50 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:04:50 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 20%|██        | 5/25 [03:52<15:41, 47.09s/it]2023-12-10 01:05:05 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:05:12 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:05:15 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:05:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:05:23 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:05:25 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:05:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:05:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:05:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:05:33 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:05:33 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:05:34 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 24%|██▍       | 6/25 [04:32<14:08, 44.65s/it]2023-12-10 01:05:45 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:05:56 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:05:59 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:06:06 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:06:07 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:06:09 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:06:16 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:06:17 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:06:17 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:06:18 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:06:18 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:06:18 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 7/25 [05:20<13:45, 45.89s/it]2023-12-10 01:06:34 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:06:44 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:06:47 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:06:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:06:55 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:06:57 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:07:04 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:07:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:07:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:07:05 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:07:05 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:07:06 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 8/25 [06:09<13:12, 46.64s/it]2023-12-10 01:07:22 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:07:33 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:07:37 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:07:44 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:07:44 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:07:47 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:07:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:07:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:07:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:07:55 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:07:55 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:07:56 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 9/25 [06:58<12:39, 47.45s/it]2023-12-10 01:08:11 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:08:18 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:08:21 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:08:28 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:08:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:08:31 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:08:38 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:08:39 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:08:39 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:08:40 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:08:40 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:08:40 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 40%|████      | 10/25 [07:38<11:18, 45.20s/it]2023-12-10 01:08:51 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:09:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:09:04 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:09:11 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:09:11 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:09:14 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:09:21 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:09:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:09:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:09:22 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:09:22 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:09:23 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 44%|████▍     | 11/25 [08:23<10:34, 45.30s/it]2023-12-10 01:09:37 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:09:43 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:09:47 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:09:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:09:54 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:09:57 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:10:04 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:10:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:10:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:10:06 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:10:06 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:10:06 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 48%|████▊     | 12/25 [09:04<09:30, 43.90s/it]2023-12-10 01:10:18 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:10:27 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:10:31 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:10:38 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:10:38 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:10:41 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:10:48 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:10:49 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:10:49 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:10:49 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:10:49 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:10:50 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 52%|█████▏    | 13/25 [09:52<09:00, 45.02s/it]2023-12-10 01:11:05 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:11:14 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:11:18 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:11:25 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:11:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:11:27 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:11:34 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:11:35 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:11:35 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:11:36 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:11:36 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:11:36 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 14/25 [10:37<08:16, 45.11s/it]2023-12-10 01:11:51 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:12:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:12:03 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:12:10 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:12:10 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:12:13 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:12:20 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:12:21 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:12:21 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:12:21 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:12:21 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:12:22 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 60%|██████    | 15/25 [11:22<07:31, 45.17s/it]2023-12-10 01:12:36 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:12:44 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:12:47 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:12:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:12:54 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:12:56 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:13:03 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:13:04 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:13:04 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:13:05 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:13:05 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:13:05 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 16/25 [12:04<06:35, 43.98s/it]2023-12-10 01:13:17 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:13:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:13:28 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:13:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:13:35 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:13:38 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:13:46 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:13:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:13:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:13:48 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:13:48 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:13:48 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 17/25 [12:47<05:49, 43.71s/it]2023-12-10 01:14:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:14:08 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:14:11 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:14:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:14:18 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:14:20 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:14:27 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:14:28 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:14:28 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:14:29 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:14:29 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:14:29 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 18/25 [13:28<04:59, 42.85s/it]2023-12-10 01:14:41 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:14:48 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:14:52 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:14:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:14:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:15:01 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:15:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:15:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:15:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:15:09 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:15:09 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:15:10 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 76%|███████▌  | 19/25 [14:07<04:10, 41.78s/it]2023-12-10 01:15:20 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:15:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:15:33 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:15:39 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:15:40 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:15:42 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:15:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:15:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:15:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:15:51 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:15:51 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:15:51 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 80%|████████  | 20/25 [14:51<03:32, 42.46s/it]2023-12-10 01:16:04 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:16:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:16:16 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:16:23 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:16:24 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:16:26 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:16:33 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:16:34 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:16:34 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:16:34 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:16:34 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:16:35 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 21/25 [15:34<02:51, 42.75s/it]2023-12-10 01:16:48 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:16:58 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:17:01 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:17:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:17:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:17:11 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:17:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:17:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:17:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:17:20 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:17:20 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:17:20 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 22/25 [16:20<02:11, 43.79s/it]2023-12-10 01:17:34 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:17:42 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:17:46 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:17:52 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:17:53 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:17:55 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:18:02 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:18:03 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:18:03 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:18:03 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:18:03 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:18:04 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 23/25 [17:03<01:26, 43.35s/it]2023-12-10 01:18:16 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:18:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:18:29 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:18:36 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:18:36 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:18:39 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:18:45 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:18:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:18:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:18:47 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:18:47 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:18:47 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 24/25 [17:47<00:43, 43.65s/it]2023-12-10 01:19:01 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:19:10 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:19:13 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:19:20 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:19:20 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:19:23 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:19:30 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:19:31 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:19:31 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:19:31 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:19:31 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:19:32 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [18:31<00:00, 44.47s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]2023-12-10 01:19:45 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:19:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:19:56 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:20:02 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:20:03 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:20:05 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:20:12 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:20:13 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:20:13 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:20:13 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:20:13 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:20:14 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/25 [00:41<16:27, 41.16s/it]2023-12-10 01:20:26 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:20:32 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:20:36 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:20:43 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:20:43 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:20:46 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:20:52 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:20:56 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:20:56 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:20:56 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:20:56 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:20:56 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/25 [01:22<15:46, 41.16s/it]2023-12-10 01:21:07 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:21:16 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:21:19 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:21:26 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:21:27 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:21:30 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:21:36 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:21:38 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:21:38 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:21:38 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:21:38 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:21:38 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 12%|█▏        | 3/25 [02:07<15:41, 42.81s/it]2023-12-10 01:21:52 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:22:01 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:22:05 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:22:11 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:22:12 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:22:14 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:22:21 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:22:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:22:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:22:23 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:22:23 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:22:23 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 16%|█▌        | 4/25 [02:51<15:14, 43.54s/it]2023-12-10 01:22:36 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:22:47 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:22:50 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:22:56 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:22:57 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:23:00 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:23:06 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:23:08 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:23:08 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:23:08 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:23:08 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:23:08 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 20%|██        | 5/25 [03:37<14:50, 44.50s/it]2023-12-10 01:23:23 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:23:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:23:32 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:23:39 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:23:40 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:23:43 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:23:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:23:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:23:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:23:51 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:23:51 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:23:51 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 24%|██▍       | 6/25 [04:17<13:31, 42.71s/it]2023-12-10 01:24:02 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:24:12 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:24:16 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:24:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:24:23 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:24:25 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:24:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:24:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:24:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:24:33 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:24:33 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:24:34 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 7/25 [05:04<13:15, 44.17s/it]2023-12-10 01:24:49 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:24:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:25:02 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:25:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:25:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:25:11 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:25:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:25:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:25:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:25:20 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:25:20 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:25:20 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 8/25 [05:49<12:37, 44.55s/it]2023-12-10 01:25:34 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:25:45 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:25:48 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:25:55 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:25:56 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:25:58 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:26:04 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:26:06 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:26:06 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:26:06 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:26:06 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:26:07 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 9/25 [06:36<12:03, 45.22s/it]2023-12-10 01:26:21 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:26:27 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:26:31 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:26:37 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:26:38 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:26:40 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:26:47 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:26:48 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:26:48 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:26:49 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:26:49 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:26:49 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 40%|████      | 10/25 [07:15<10:47, 43.19s/it]2023-12-10 01:27:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:27:08 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:27:12 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:27:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:27:19 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:27:21 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:27:28 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:27:29 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:27:29 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:27:29 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:27:29 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:27:30 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 44%|████▍     | 11/25 [07:58<10:04, 43.15s/it]2023-12-10 01:27:43 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:27:49 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:27:53 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:28:00 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:28:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:28:02 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:28:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:28:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:28:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:28:11 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:28:11 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:28:11 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 48%|████▊     | 12/25 [08:37<09:04, 41.89s/it]2023-12-10 01:28:22 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:28:31 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:28:34 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:28:41 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:28:41 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:28:44 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:28:50 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:28:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:28:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:28:52 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:28:52 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:28:53 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 52%|█████▏    | 13/25 [09:21<08:32, 42.72s/it]2023-12-10 01:29:06 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:29:16 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:29:19 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:29:25 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:29:26 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:29:28 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:29:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:29:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:29:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:29:37 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:29:37 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:29:37 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 14/25 [10:05<07:53, 43.01s/it]2023-12-10 01:29:50 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:29:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:30:03 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:30:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:30:11 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:30:14 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:30:20 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:30:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:30:22 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:30:22 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:30:22 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:30:23 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 60%|██████    | 15/25 [10:51<07:20, 44.02s/it]2023-12-10 01:30:36 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:30:44 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:30:47 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:30:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:30:55 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:30:57 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:31:03 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:31:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:31:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:31:05 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:31:05 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:31:06 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 16/25 [11:32<06:28, 43.15s/it]2023-12-10 01:31:18 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:31:26 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:31:30 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:31:37 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:31:37 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:31:39 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:31:46 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:31:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:31:47 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:31:48 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:31:48 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:31:48 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 17/25 [12:15<05:43, 42.92s/it]2023-12-10 01:32:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:32:07 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:32:11 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:32:17 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:32:18 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:32:21 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:32:27 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:32:28 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:32:28 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:32:29 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:32:29 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:32:29 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 18/25 [12:56<04:57, 42.46s/it]2023-12-10 01:32:41 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:32:48 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:32:51 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:32:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:32:58 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:33:01 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:33:07 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:33:08 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:33:08 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:33:09 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:33:09 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:33:09 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 76%|███████▌  | 19/25 [13:35<04:08, 41.36s/it]2023-12-10 01:33:20 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:33:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:33:32 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:33:39 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:33:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:33:42 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:33:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:33:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:33:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:33:50 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:33:50 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:33:51 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 80%|████████  | 20/25 [14:19<03:30, 42.09s/it]2023-12-10 01:34:04 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:34:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:34:16 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:34:23 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:34:23 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:34:25 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:34:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:34:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:34:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:34:34 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:34:34 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:34:34 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 21/25 [15:02<02:49, 42.39s/it]2023-12-10 01:34:47 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:34:57 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:35:01 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:35:07 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:35:08 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:35:10 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:35:17 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:35:18 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:35:18 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:35:19 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:35:19 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:35:19 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 22/25 [15:48<02:10, 43.61s/it]2023-12-10 01:35:33 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:35:42 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:35:45 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:35:52 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:35:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:35:55 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:36:02 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:36:03 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:36:03 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:36:03 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:36:03 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:36:04 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 23/25 [16:31<01:26, 43.39s/it]2023-12-10 01:36:16 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:36:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:36:29 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:36:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:36:36 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:36:38 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:36:45 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:36:46 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:36:46 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:36:46 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:36:46 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:36:47 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 24/25 [17:15<00:43, 43.56s/it]2023-12-10 01:37:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:37:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:37:13 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:37:20 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:37:20 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:37:22 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:37:29 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:37:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:37:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:37:31 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:37:31 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:37:31 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [17:59<00:00, 43.18s/it]\n"
     ]
    }
   ],
   "source": [
    "data_file = f\"{config['outputDir']}/zookeeper_with_embeddings.csv\"\n",
    "df_with_embeddings = process_dataset(data_file)\n",
    "df_with_embeddings.to_csv(data_file.replace(\".csv\", \"_with_metrics.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T08:37:44.620534800Z",
     "start_time": "2023-12-10T07:40:34.056472500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2023-12-10 01:37:44 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:37:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:37:55 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:38:02 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:38:02 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:38:04 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:38:11 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:38:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:38:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:38:15 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:38:15 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:38:16 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/25 [00:43<17:19, 43.30s/it]2023-12-10 01:38:27 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:38:34 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:38:37 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:38:44 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:38:45 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:38:47 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:38:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:38:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:38:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:38:55 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:38:55 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:38:56 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/25 [01:21<15:30, 40.48s/it]2023-12-10 01:39:06 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:39:15 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:39:18 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:39:25 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:39:26 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:39:28 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:39:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:39:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:39:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:39:37 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:39:37 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:39:37 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 12%|█▏        | 3/25 [02:06<15:30, 42.29s/it]2023-12-10 01:39:50 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:39:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:40:03 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:40:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:40:10 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:40:12 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:40:19 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:40:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:40:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:40:20 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:40:20 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:40:21 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 16%|█▌        | 4/25 [02:50<15:02, 43.00s/it]2023-12-10 01:40:34 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:40:46 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:40:50 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:40:57 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:40:57 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:40:59 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:41:06 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:41:08 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:41:08 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:41:08 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:41:08 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:41:09 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 20%|██        | 5/25 [03:38<14:58, 44.93s/it]2023-12-10 01:41:23 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:41:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:41:33 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:41:39 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:41:40 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:41:42 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:41:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:41:51 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:41:51 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:41:51 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:41:51 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:41:52 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 24%|██▍       | 6/25 [04:18<13:41, 43.26s/it]2023-12-10 01:42:03 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:42:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:42:16 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:42:23 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:42:24 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:42:26 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:42:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:42:34 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:42:34 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:42:34 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:42:34 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:42:35 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 7/25 [05:04<13:14, 44.12s/it]2023-12-10 01:42:49 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:42:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:43:02 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:43:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:43:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:43:12 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:43:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:43:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:43:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:43:20 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:43:20 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:43:21 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 8/25 [05:50<12:41, 44.80s/it]2023-12-10 01:43:35 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:43:45 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:43:48 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:43:55 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:43:55 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:43:58 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:44:04 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:44:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:44:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:44:06 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:44:06 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:44:06 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 9/25 [06:36<12:00, 45.06s/it]2023-12-10 01:44:21 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:44:27 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:44:31 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:44:38 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:44:38 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:44:40 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:44:47 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:44:48 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:44:48 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:44:49 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:44:49 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:44:49 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 40%|████      | 10/25 [07:15<10:48, 43.23s/it]2023-12-10 01:45:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:45:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:45:12 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:45:19 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:45:19 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:45:21 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:45:28 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:45:29 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:45:29 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:45:30 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:45:30 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:45:30 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 44%|████▍     | 11/25 [07:58<10:05, 43.24s/it]2023-12-10 01:45:43 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:45:50 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:45:53 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:46:00 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:46:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:46:02 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:46:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:46:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:46:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:46:11 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:46:11 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:46:11 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 48%|████▊     | 12/25 [08:37<09:04, 41.86s/it]2023-12-10 01:46:22 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:46:31 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:46:34 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:46:41 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:46:41 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:46:44 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:46:51 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:46:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:46:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:46:52 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:46:52 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:46:53 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 52%|█████▏    | 13/25 [09:22<08:32, 42.69s/it]2023-12-10 01:47:06 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:47:15 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:47:18 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:47:25 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:47:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:47:28 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:47:34 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:47:35 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:47:35 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:47:36 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:47:36 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:47:36 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 14/25 [10:05<07:50, 42.80s/it]2023-12-10 01:47:49 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:47:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:48:02 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:48:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:48:10 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:48:12 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:48:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:48:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:48:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:48:20 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:48:20 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:48:20 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 60%|██████    | 15/25 [10:49<07:13, 43.36s/it]2023-12-10 01:48:34 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:48:42 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:48:45 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:48:52 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:48:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:48:54 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:49:01 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:49:03 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:49:03 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:49:03 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:49:03 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:49:04 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 16/25 [11:31<06:24, 42.75s/it]2023-12-10 01:49:15 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:49:23 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:49:26 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:49:33 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:49:33 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:49:36 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:49:42 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:49:44 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:49:44 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:49:44 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:49:44 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:49:44 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 17/25 [12:12<05:37, 42.23s/it]2023-12-10 01:49:56 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:50:04 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:50:07 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:50:14 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:50:14 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:50:17 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:50:24 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:50:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:50:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:50:25 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:50:25 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:50:26 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 18/25 [12:53<04:53, 41.92s/it]2023-12-10 01:50:38 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:50:44 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:50:47 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:50:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:50:54 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:50:57 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:51:03 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:51:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:51:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:51:05 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:51:05 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:51:05 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 76%|███████▌  | 19/25 [13:32<04:05, 40.97s/it]2023-12-10 01:51:16 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:51:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:51:29 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:51:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:51:36 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:51:38 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:51:45 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:51:46 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:51:46 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:51:46 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:51:46 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:51:47 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 80%|████████  | 20/25 [14:15<03:28, 41.77s/it]2023-12-10 01:52:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:52:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:52:13 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:52:19 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:52:20 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:52:22 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:52:29 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:52:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:52:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:52:31 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:52:31 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:52:31 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 21/25 [15:00<02:50, 42.56s/it]2023-12-10 01:52:44 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:52:55 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:52:58 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:53:05 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:53:05 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:53:07 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:53:14 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:53:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:53:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:53:16 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:53:16 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:53:16 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 22/25 [15:46<02:10, 43.56s/it]2023-12-10 01:53:30 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:53:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:53:42 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:53:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:53:49 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:53:52 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:53:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:54:00 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:54:00 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:54:00 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:54:00 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:54:01 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 23/25 [16:28<01:26, 43.33s/it]2023-12-10 01:54:13 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:54:22 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:54:25 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:54:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:54:32 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:54:35 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:54:41 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:54:43 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:54:43 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:54:43 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:54:43 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:54:43 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 24/25 [17:12<00:43, 43.52s/it]2023-12-10 01:54:57 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:55:06 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:55:10 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:55:16 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:55:17 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:55:19 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:55:26 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:55:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:55:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:55:28 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:55:28 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:55:28 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [17:56<00:00, 43.07s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]2023-12-10 01:55:41 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:55:49 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:55:52 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:55:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:55:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:56:02 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:56:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:56:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:56:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:56:10 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:56:10 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:56:11 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/25 [00:41<16:39, 41.64s/it]2023-12-10 01:56:22 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:56:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:56:32 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:56:39 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:56:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:56:42 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:56:48 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:56:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:56:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:56:50 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:56:50 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:56:50 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/25 [01:19<15:13, 39.71s/it]2023-12-10 01:57:01 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:57:10 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:57:13 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:57:20 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:57:21 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:57:23 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:57:30 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:57:31 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:57:31 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:57:32 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:57:32 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:57:32 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 12%|█▏        | 3/25 [02:04<15:21, 41.89s/it]2023-12-10 01:57:45 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:57:54 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:57:58 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:58:04 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:58:05 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:58:07 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:58:14 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:58:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:58:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:58:15 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:58:15 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:58:16 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 16%|█▌        | 4/25 [02:48<14:56, 42.69s/it]2023-12-10 01:58:29 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:58:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:58:43 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:58:50 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:58:50 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:58:53 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:58:59 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:59:02 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:59:02 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:59:03 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:59:03 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:59:04 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 20%|██        | 5/25 [03:36<14:54, 44.70s/it]2023-12-10 01:59:17 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 01:59:24 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:59:28 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 01:59:34 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:59:35 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 01:59:37 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 01:59:44 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 01:59:45 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 01:59:45 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 01:59:46 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 01:59:46 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 01:59:46 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 24%|██▍       | 6/25 [04:15<13:32, 42.76s/it]2023-12-10 01:59:56 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:00:07 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:00:10 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:00:17 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:00:17 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:00:19 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:00:26 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:00:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:00:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:00:28 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:00:28 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:00:28 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 7/25 [05:01<13:06, 43.69s/it]2023-12-10 02:00:42 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:00:52 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:00:55 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:01:02 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:01:04 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:01:06 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:01:13 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:01:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:01:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:01:15 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:01:15 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:01:15 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 8/25 [05:48<12:40, 44.76s/it]2023-12-10 02:01:29 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:01:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:01:43 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:01:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:01:50 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:01:52 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:01:59 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:02:00 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:02:00 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:02:00 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:02:00 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:02:01 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 9/25 [06:34<12:01, 45.07s/it]2023-12-10 02:02:15 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:02:22 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:02:25 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:02:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:02:32 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:02:35 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:02:41 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:02:42 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:02:42 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:02:43 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:02:43 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:02:43 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 40%|████      | 10/25 [07:12<10:46, 43.12s/it]2023-12-10 02:02:54 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:03:02 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:03:05 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:03:12 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:03:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:03:15 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:03:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:03:23 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:03:23 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:03:24 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:03:24 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:03:24 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 44%|████▍     | 11/25 [07:56<10:04, 43.20s/it]2023-12-10 02:03:37 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:03:43 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:03:47 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:03:53 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:03:54 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:03:56 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:04:03 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:04:04 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:04:04 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:04:04 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:04:04 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:04:05 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 48%|████▊     | 12/25 [08:34<09:01, 41.62s/it]2023-12-10 02:04:15 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:04:24 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:04:28 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:04:34 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:04:35 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:04:37 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:04:44 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:04:45 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:04:45 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:04:46 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:04:46 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:04:46 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 52%|█████▏    | 13/25 [09:19<08:31, 42.62s/it]2023-12-10 02:05:00 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:05:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:05:12 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:05:19 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:05:19 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:05:22 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:05:28 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:05:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:05:30 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:05:30 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:05:30 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:05:30 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 14/25 [10:02<07:51, 42.88s/it]2023-12-10 02:05:43 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:05:53 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:05:56 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:06:03 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:06:04 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:06:06 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:06:12 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:06:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:06:14 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:06:14 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:06:14 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:06:15 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 60%|██████    | 15/25 [10:47<07:13, 43.38s/it]2023-12-10 02:06:28 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:06:36 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:06:39 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:06:46 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:06:46 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:06:49 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:06:55 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:06:57 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:06:57 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:06:57 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:06:57 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:06:57 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 16/25 [11:28<06:25, 42.79s/it]2023-12-10 02:07:09 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:07:17 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:07:20 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:07:27 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:07:27 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:07:30 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:07:36 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:07:38 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:07:38 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:07:38 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:07:38 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:07:38 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 17/25 [12:09<05:37, 42.25s/it]2023-12-10 02:07:50 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:07:58 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:08:01 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:08:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:08:09 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:08:11 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:08:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:08:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:08:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:08:20 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:08:20 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:08:20 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 18/25 [12:51<04:54, 42.11s/it]2023-12-10 02:08:32 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:08:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:08:42 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:08:48 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:08:49 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:08:51 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:08:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:08:59 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:08:59 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:09:00 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:09:00 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:09:00 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 76%|███████▌  | 19/25 [13:29<04:06, 41.02s/it]2023-12-10 02:09:11 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:09:19 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:09:23 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:09:30 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:09:30 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:09:33 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:09:39 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:09:41 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:09:41 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:09:41 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:09:41 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:09:41 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 80%|████████  | 20/25 [14:13<03:29, 41.84s/it]2023-12-10 02:09:54 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:10:03 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:10:06 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:10:13 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:10:14 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:10:16 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:10:23 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:10:24 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:10:24 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:10:24 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:10:24 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:10:25 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 21/25 [14:56<02:49, 42.28s/it]2023-12-10 02:10:38 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:10:48 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:10:51 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:10:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:10:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:11:01 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:11:07 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:11:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:11:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:11:09 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:11:09 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:11:10 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 22/25 [15:43<02:10, 43.47s/it]2023-12-10 02:11:24 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:11:32 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:11:36 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:11:43 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:11:43 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:11:46 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:11:52 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:11:54 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:11:54 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:11:54 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:11:54 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:11:54 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 23/25 [16:26<01:26, 43.40s/it]2023-12-10 02:12:07 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:12:17 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:12:20 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:12:26 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:12:28 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:12:31 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:12:37 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:12:39 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:12:39 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:12:40 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:12:40 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:12:40 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 24/25 [17:12<00:44, 44.23s/it]2023-12-10 02:12:53 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:13:02 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:13:06 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:13:13 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:13:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:13:16 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:13:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:13:23 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:13:23 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:13:24 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:13:24 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:13:24 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [17:56<00:00, 43.06s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]2023-12-10 02:13:37 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:13:45 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:13:48 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:13:55 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:13:55 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:13:58 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:14:05 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:14:06 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:14:06 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:14:06 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:14:06 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:14:07 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/25 [00:41<16:25, 41.07s/it]2023-12-10 02:14:18 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:14:25 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:14:28 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:14:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:14:35 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:14:37 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:14:44 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:14:45 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:14:45 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:14:46 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:14:46 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:14:46 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/25 [01:19<15:05, 39.39s/it]2023-12-10 02:14:57 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:15:06 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:15:09 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:15:16 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:15:17 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:15:19 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:15:26 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:15:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:15:27 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:15:28 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:15:28 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:15:28 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 12%|█▏        | 3/25 [02:03<15:19, 41.79s/it]2023-12-10 02:15:41 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:15:50 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:15:54 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:16:00 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:16:01 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:16:03 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:16:10 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:16:11 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:16:11 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:16:11 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:16:11 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:16:12 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 16%|█▌        | 4/25 [02:47<14:54, 42.59s/it]2023-12-10 02:16:25 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:16:35 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:16:39 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:16:45 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:16:46 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:16:48 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:16:55 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:16:56 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:16:56 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:16:57 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:16:57 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:16:58 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 20%|██        | 5/25 [03:34<14:41, 44.09s/it]2023-12-10 02:17:12 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:17:18 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:17:21 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:17:28 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:17:30 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:17:33 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:17:40 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:17:42 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:17:42 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:17:42 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:17:42 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:17:43 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 24%|██▍       | 6/25 [04:16<13:41, 43.22s/it]2023-12-10 02:17:53 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:18:03 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:18:07 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:18:13 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:18:14 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:18:16 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:18:23 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:18:24 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:18:24 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:18:25 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:18:25 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:18:25 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 7/25 [05:01<13:11, 43.99s/it]2023-12-10 02:18:39 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:18:49 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:18:53 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:18:59 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:19:00 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:19:02 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:19:09 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:19:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:19:10 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:19:10 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:19:10 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:19:11 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 8/25 [05:47<12:36, 44.50s/it]2023-12-10 02:19:25 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:19:35 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:19:38 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:19:45 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:19:45 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:19:47 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:19:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:19:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:19:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:19:56 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:19:56 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:19:56 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 9/25 [06:32<11:58, 44.89s/it]2023-12-10 02:20:10 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:20:17 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:20:21 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:20:27 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:20:28 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:20:30 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:20:37 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:20:38 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:20:38 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:20:38 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:20:38 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:20:39 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 40%|████      | 10/25 [07:11<10:45, 43.01s/it]2023-12-10 02:20:49 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:20:58 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:21:01 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:21:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:21:08 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:21:11 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:21:18 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:21:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:21:19 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:21:19 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:21:19 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:21:20 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 44%|████▍     | 11/25 [07:55<10:04, 43.16s/it]2023-12-10 02:21:33 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:21:39 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:21:42 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:21:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:21:49 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:21:52 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:21:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:21:59 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:21:59 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:22:00 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:22:00 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:22:00 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 48%|████▊     | 12/25 [08:33<09:02, 41.72s/it]2023-12-10 02:22:11 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:22:20 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:22:24 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:22:31 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:22:31 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:22:34 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:22:40 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:22:41 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:22:41 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:22:42 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:22:42 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:22:42 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 52%|█████▏    | 13/25 [09:18<08:32, 42.67s/it]2023-12-10 02:22:56 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:23:05 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:23:08 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:23:14 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:23:15 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:23:18 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:23:24 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:23:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:23:25 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:23:26 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:23:26 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:23:26 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 14/25 [10:01<07:51, 42.88s/it]2023-12-10 02:23:39 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:23:48 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:23:52 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:23:58 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:23:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:24:01 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:24:08 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:24:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:24:09 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:24:10 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:24:10 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:24:10 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 60%|██████    | 15/25 [10:46<07:12, 43.29s/it]2023-12-10 02:24:23 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:24:31 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:24:35 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:24:41 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:24:42 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:24:44 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:24:51 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:24:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:24:52 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:24:53 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:24:53 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:24:53 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 16/25 [11:27<06:24, 42.73s/it]2023-12-10 02:25:05 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:25:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:25:16 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:25:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:25:23 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:25:25 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:25:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:25:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:25:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:25:33 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:25:33 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:25:34 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 17/25 [12:08<05:38, 42.31s/it]2023-12-10 02:25:46 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:25:54 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:25:58 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:26:04 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:26:05 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:26:07 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:26:14 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:26:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:26:15 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:26:15 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:26:15 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:26:16 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 18/25 [12:50<04:54, 42.03s/it]2023-12-10 02:26:28 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:26:34 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:26:37 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:26:44 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:26:44 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:26:47 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:26:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:26:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:26:55 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:26:55 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:26:55 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:26:56 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 76%|███████▌  | 19/25 [13:29<04:06, 41.08s/it]2023-12-10 02:27:06 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:27:15 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:27:19 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:27:25 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:27:26 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:27:28 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:27:35 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:27:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:27:36 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:27:36 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:27:36 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:27:37 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 80%|████████  | 20/25 [14:12<03:29, 41.82s/it]2023-12-10 02:27:50 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:27:59 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:28:02 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:28:10 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:28:10 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:28:12 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:28:19 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:28:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:28:20 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:28:21 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:28:21 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:28:21 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 21/25 [14:56<02:49, 42.49s/it]2023-12-10 02:28:34 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:28:44 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:28:48 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:28:54 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:28:55 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:28:57 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:29:04 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:29:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:29:05 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:29:05 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:29:05 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:29:06 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 22/25 [15:42<02:10, 43.52s/it]2023-12-10 02:29:20 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:29:29 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:29:32 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:29:39 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:29:40 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:29:42 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:29:49 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:29:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:29:50 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:29:50 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:29:50 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:29:51 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 23/25 [16:26<01:26, 43.48s/it]2023-12-10 02:30:03 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:30:13 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:30:16 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:30:22 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:30:23 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:30:26 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:30:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:30:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:30:33 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:30:34 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:30:34 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:30:34 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 24/25 [17:10<00:43, 43.81s/it]2023-12-10 02:30:48 | INFO | absl | Using default tokenizer.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-12-10 02:30:57 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_STS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:31:00 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-12-10 02:31:07 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1000, log_format='tqdm', tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='sentence_prediction', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='sentence_prediction', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=16, required_batch_size_multiple=1, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_tokens_valid=4400, max_sentences_valid=16, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[2e-05], use_bmuf=False, save_dir='checkpoints', restore_file='model.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=214, end_learning_rate=0.0, power=1.0, total_num_update=3598, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', num_classes=1, init_token=0, separator_token=2, regression_target=True, no_shuffle=False, truncate_sequence=False, max_positions=512, dropout=0.1, attention_dropout=0.1, encoder_layers=24, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, tokens_per_sample=512, load_checkpoint_heads=True, max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'sentence_prediction', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_STS', 'num_classes': 1, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': 'none', 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': True, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 214, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3598.0, 'lr': [2e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:31:08 | INFO | fairseq.file_utils | loading archive file C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\nubia_score\\pretrained/roBERTa_MNLI\n",
      "2023-12-10 02:31:10 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-12-10 02:31:16 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', tbmf_wrapper=False, seed=8, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, debug=False, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=3, skip_invalid_size_inputs_valid_test=False, max_tokens=4400, max_sentences=32, required_batch_size_multiple=1, dataset_impl='cached', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, max_sentences_valid=32, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, arch='roberta_large', max_epoch=10, max_update=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[1e-05], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_save_optimizer_state=True, best_checkpoint_metric='accuracy', maximize_best_checkpoint_metric=True, label_smoothing=0.0, save_predictions=None, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.1, force_anneal=None, warmup_updates=30968, end_learning_rate=0.0, power=1.0, total_num_update=123873, max_positions=512, num_classes=3, init_token=0, separator_token=2, regression_target=False, no_shuffle=False, truncate_sequence=False, bagging=False, remove_sentence_classification_head=True, remove_head=True, pooler_dropout=0.3, dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, activation_fn='gelu', pooler_activation_fn='tanh', tokens_per_sample=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\camer\\\\PycharmProjects\\\\CloudComputingCapstone\\\\venv\\\\lib\\\\site-packages\\\\nubia_score\\\\pretrained\\\\roBERTa_MNLI', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-12-10 02:31:18 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "2023-12-10 02:31:18 | INFO | pytorch_transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-12-10 02:31:18 | INFO | pytorch_transformers.modeling_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "2023-12-10 02:31:18 | INFO | pytorch_transformers.modeling_utils | Model config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2023-12-10 02:31:19 | INFO | pytorch_transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\camer\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "C:\\Users\\camer\\PycharmProjects\\CloudComputingCapstone\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPRegressor from version 0.22.2.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [17:54<00:00, 42.98s/it]\n"
     ]
    }
   ],
   "source": [
    "data_file = f\"{config['outputDir']}/zookeeper_without_embeddings.csv\"\n",
    "df_without_embeddings = process_dataset(data_file)\n",
    "df_without_embeddings.to_csv(data_file.replace(\".csv\", \"_with_metrics.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:32.310787300Z",
     "start_time": "2023-12-10T08:37:44.623534800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "ref_bleu_scores = df_with_embeddings[\"ref BLEU\"].tolist()\n",
    "ref_rouge_scores = df_with_embeddings[\"ref ROUGE\"].tolist()\n",
    "ref_meteor_scores = df_with_embeddings[\"ref METEOR\"].tolist()\n",
    "ref_bert_scores = df_with_embeddings[\"ref BERT\"].tolist()\n",
    "ref_bleurt_scores = df_with_embeddings[\"ref BLEURT\"].tolist()\n",
    "ref_nubia_scores = df_with_embeddings[\"ref NUBIA\"].tolist()\n",
    "ref_labels = [\"Reference Summaries\" for _ in range(len(df_with_embeddings))]\n",
    "\n",
    "gpt3_bleu_scores_embed = df_with_embeddings[\"gpt3 BLEU\"].tolist()\n",
    "gpt3_rouge_scores_embed = df_with_embeddings[\"gpt3 ROUGE\"].tolist()\n",
    "gpt3_meteor_scores_embed = df_with_embeddings[\"gpt3 METEOR\"].tolist()\n",
    "gpt3_bert_scores_embed = df_with_embeddings[\"gpt3 BERT\"].tolist()\n",
    "gpt3_bleurt_scores_embed = df_with_embeddings[\"gpt3 BLEURT\"].tolist()\n",
    "gpt3_nubia_scores_embed = df_with_embeddings[\"gpt3 NUBIA\"].tolist()\n",
    "gpt3_labels_embed = [\"ChatGPT 3.5 w/out embeddings\" for _ in range(len(df_with_embeddings))]\n",
    "\n",
    "gpt4_bleu_scores_embed = df_with_embeddings[\"gpt4 BLEU\"].tolist()\n",
    "gpt4_rouge_scores_embed = df_with_embeddings[\"gpt4 ROUGE\"].tolist()\n",
    "gpt4_meteor_scores_embed = df_with_embeddings[\"gpt4 METEOR\"].tolist()\n",
    "gpt4_bert_scores_embed = df_with_embeddings[\"gpt4 BERT\"].tolist()\n",
    "gpt4_bleurt_scores_embed = df_with_embeddings[\"gpt4 BLEURT\"].tolist()\n",
    "gpt4_nubia_scores_embed = df_with_embeddings[\"gpt4 NUBIA\"].tolist()\n",
    "gpt4_labels_embed = [\"ChatGPT 4 w/out embeddings\" for _ in range(len(df_with_embeddings))]\n",
    "\n",
    "gpt3_bleu_scores_no_embed = df_without_embeddings[\"gpt3 BLEU\"].tolist()\n",
    "gpt3_rouge_scores_no_embed = df_without_embeddings[\"gpt3 ROUGE\"].tolist()\n",
    "gpt3_meteor_scores_no_embed = df_without_embeddings[\"gpt3 METEOR\"].tolist()\n",
    "gpt3_bert_scores_no_embed = df_without_embeddings[\"gpt3 BERT\"].tolist()\n",
    "gpt3_bleurt_scores_no_embed = df_without_embeddings[\"gpt3 BLEURT\"].tolist()\n",
    "gpt3_nubia_scores_no_embed = df_without_embeddings[\"gpt3 NUBIA\"].tolist()\n",
    "gpt3_labels_no_embed = [\"ChatGPT 3.5 w/ embeddings\" for _ in range(len(df_without_embeddings))]\n",
    "\n",
    "gpt4_bleu_scores_no_embed = df_without_embeddings[\"gpt4 BLEU\"].tolist()\n",
    "gpt4_rouge_scores_no_embed = df_without_embeddings[\"gpt4 ROUGE\"].tolist()\n",
    "gpt4_meteor_scores_no_embed = df_without_embeddings[\"gpt4 METEOR\"].tolist()\n",
    "gpt4_bert_scores_no_embed = df_without_embeddings[\"gpt4 BERT\"].tolist()\n",
    "gpt4_bleurt_scores_no_embed = df_without_embeddings[\"gpt4 BLEURT\"].tolist()\n",
    "gpt4_nubia_scores_no_embed = df_without_embeddings[\"gpt4 NUBIA\"].tolist()\n",
    "gpt4_labels_no_embed = [\"ChatGPT 4 w/ embeddings\" for _ in range(len(df_without_embeddings))]\n",
    "\n",
    "score_df = pd.DataFrame(\n",
    "  {\n",
    "    \"Summaries Source\": ref_labels + gpt3_labels_no_embed + gpt3_labels_embed + gpt4_labels_no_embed + gpt4_labels_embed,\n",
    "    \"BLEU Score\": ref_bleu_scores + gpt3_bleu_scores_no_embed + gpt3_bleu_scores_embed + gpt4_bleu_scores_no_embed + gpt4_bleu_scores_embed,\n",
    "    \"ROUGE Score\": ref_rouge_scores + gpt3_rouge_scores_no_embed + gpt3_rouge_scores_embed + gpt4_rouge_scores_no_embed + gpt4_rouge_scores_embed,\n",
    "    \"METEOR Score\": ref_meteor_scores + gpt3_meteor_scores_no_embed + gpt3_meteor_scores_embed + gpt4_meteor_scores_no_embed + gpt4_meteor_scores_embed,\n",
    "    \"BERT Score\": ref_bert_scores + gpt3_bert_scores_no_embed + gpt3_bert_scores_embed + gpt4_bert_scores_no_embed + gpt4_bert_scores_embed,\n",
    "    \"BLEURT Score\": ref_bleurt_scores + gpt3_bleurt_scores_no_embed + gpt3_bleurt_scores_embed + gpt4_bleurt_scores_no_embed + gpt4_bleurt_scores_embed,\n",
    "    \"NUBIA Score\": ref_nubia_scores + gpt3_nubia_scores_no_embed + gpt3_nubia_scores_embed + gpt4_nubia_scores_no_embed + gpt4_nubia_scores_embed,\n",
    "  }\n",
    ")\n",
    "\n",
    "score_df.to_csv(\"out/scores.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:32.355783700Z",
     "start_time": "2023-12-10T09:31:32.316788400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "sns.set_style(\"whitegrid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:32.365783900Z",
     "start_time": "2023-12-10T09:31:32.343786600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "sns.boxplot(y='BLEU Score', x='Summaries Source', data=score_df, width=0.5, showfliers=False, hue='Summaries Source')\n",
    "plt.title(\"BLEU Scores for Generated Log Summaries\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/img/bleu-scores.png\", dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:33.477309500Z",
     "start_time": "2023-12-10T09:31:32.359783800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "sns.boxplot(y='ROUGE Score', x='Summaries Source', data=score_df, width=0.5, showfliers=False, hue='Summaries Source')\n",
    "plt.title(\"ROUGE Scores for Generated Log Summaries\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/img/rouge-scores.png\", dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:34.653450300Z",
     "start_time": "2023-12-10T09:31:33.479309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "sns.boxplot(y='METEOR Score', x='Summaries Source', data=score_df, width=0.5, showfliers=False, hue='Summaries Source')\n",
    "plt.title(\"METEOR Scores for Generated Log Summaries\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/img/meteor-scores.png\", dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:35.776413600Z",
     "start_time": "2023-12-10T09:31:34.652449100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "sns.boxplot(y='BERT Score', x='Summaries Source', data=score_df, width=0.5, showfliers=False, hue='Summaries Source')\n",
    "plt.title(\"BERT Scores for Generated Log Summaries\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/img/bert-scores.png\", dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:36.871632900Z",
     "start_time": "2023-12-10T09:31:35.777415600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "sns.boxplot(y='BLEURT Score', x='Summaries Source', data=score_df, width=0.5, showfliers=False, hue='Summaries Source')\n",
    "plt.title(\"BLEURT Scores for Generated Log Summaries\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/img/bleurt-scores.png\", dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T09:31:38.025413400Z",
     "start_time": "2023-12-10T09:31:36.873630300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "sns.boxplot(y='NUBIA Score', x='Summaries Source', data=score_df, width=0.5, showfliers=False, hue='Summaries Source')\n",
    "plt.title(\"NUBIA Scores for Generated Log Summaries\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/img/nubia-scores.png\", dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T19:52:28.607868600Z",
     "start_time": "2023-12-10T19:52:27.397634700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
