// Max's papers

@article{li2022an,
author = {Li, Yichen and Zhang, Xu and He, Shilin and Chen, Zhuangbin and Kang, Yu and Liu, Jinyang and Li, Liqun and Dang, Yingnong and Gao, Feng and Xu, Zhangwei and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei and Lyu, Michael R.},
title = {An Intelligent Framework for Timely, Accurate, and Comprehensive Cloud Incident Detection},
year = {2022},
month = {June},
abstract = {Cloud incidents (service interruptions or performance degradation) dramatically degrade the reliability of large-scale cloud systems, causing customer dissatisfaction and revenue loss. With years of efforts, cloud providers are able to solve most incidents automatically and rapidly. The secret of this ability is intelligent incident detection. Only when incidents are detected timely, accurately, and comprehensively, can they be diagnosed and mitigated at a satisfiable speed. To overcome the limitations of traditional rule-based detection, we carried out years of incident detection research. We developed a comprehensive AIOps (Artificial Intelligence for IT Operations) framework for incident detection containing a set of data-driven methods. This paper shares our recent experience of developing and deploying such an intelligent incident detection system at Microsoft. We first discuss the real-world challenges of incident detection that constitute the pain points of engineers. Then, we summarize our intelligent solutions proposed in recent years to tackle these challenges. Finally, we show the deployment of the incident detection AIOps framework and demonstrate its practical benefits conveyed to Microsoft cloud services with real cases.},
url = {https://www.microsoft.com/en-us/research/publication/an-intelligent-framework-for-timely-accurate-and-comprehensive-cloud-incident-detection/},
pages = {1-7},
journal = {ACM SIGOPS Operating Systems Review},
volume = {56},
number = {1},
}

@inproceedings{chen2020aiops,
author = {Chen, Zhuangbin and ...  and Lin, Qingwei},
title = {AIOps Innovations in Incident Management for Cloud Services},
booktitle = {Cloud Intelligence Workshop, AAAI'20},
year = {2020},
month = {February},
abstract = {While remarkable advances have been achieved in cloud computing infrastructure, the way incidents (unplanned interruptions or outages of a service/product) are managed needs to be as agile and dynamics as the cloud itself. In practice, incident management is conducted through analysing a huge amount of monitoring data collected at the runtime of services. Given its data-driven nature, we deem AIOps innovations as essential to empowering cloud systems to provide more reliable online services and applications by incorporating more intelligence into the entire workflow of incident management. This paper presents a project showcase of our AIOps practices towards these goals at Microsoft. First, we brief the incident management procedure and its corresponding real-world challenges. Then, we elaborate the ML & AI techniques used for mitigating such challenges and share some application results to demonstrate the intelligence and benefits conveyed to Microsoft service products.},
url = {https://www.microsoft.com/en-us/research/publication/aiops-innovations-in-incident-management-for-cloud-services/}
}

@misc{ruoccofabrizio,
  title = {Azure OpenAI Embeddings QnA},
  author = {ruoccofabrizio},
  year = {2023},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/ruoccofabrizio/azure-open-ai-embeddings-qna}},
  commit = {2d8feac}
}

@inproceedings{mani2023enhancing,
author = {Mani, Sathiya Kumaran and Zhou, Yajie and Hsieh, Kevin and Segarra, Santiago and Chandra, Ranveer and Kandula, Srikanth},
title = {Enhancing Network Management Using Code Generated by Large Language Models},
booktitle = {ACM Workshop on Hot Topics in Networks (HotNets)},
year = {2023},
month = {November},
abstract = {Analyzing network topologies and communication graphs plays a crucial role in contemporary network management. However, the absence of a cohesive approach leads to a challenging learning curve, heightened errors, and inefficiencies. In this paper, we introduce a novel approach to facilitate a natural-language-based network management experience, utilizing large language models (LLMs) to generate task-specific code from natural language queries. This method tackles the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code, eliminating the need to share network data with LLMs, and concentrating on application-specific requests combined with general program synthesis techniques. We design and evaluate a prototype system using benchmark applications, showcasing high accuracy, cost-effectiveness, and the potential for further enhancements using complementary program synthesis techniques.},
url = {https://www.microsoft.com/en-us/research/publication/enhancing-network-management-using-code-generated-by-large-language-models/},
}

// Cameron's papers

@inproceedings{aiops-challenges,
    author = {Dang, Yingnong and Lin, Qingwei and Huang, Peng},
    title = {AIOps: Real-World Challenges and Research Innovations},
    year = {2019},
    publisher = {IEEE Press},
    url = {https://doi-org.proxy2.library.illinois.edu/10.1109/ICSE-Companion.2019.00023},
    doi = {10.1109/ICSE-Companion.2019.00023},
    abstract = {AIOps is about empowering software and service engineers (e.g., developers, program managers, support engineers, site reliability engineers) to efficiently and effectively build and operate online services and applications at scale with artificial intelligence (AI) and machine learning (ML) techniques. AIOps can help improve service quality and customer satisfaction, boost engineering productivity, and reduce operational cost. In this technical briefing, we first summarize the real-world challenges in building AIOps solutions based on our practice and experience in Microsoft. We then propose a roadmap of AIOps related research directions, and share a few successful AIOps solutions we have built for Microsoft service products.},
    booktitle = {Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings},
    pages = {4–5},
    numpages = {2},
    keywords = {AIOps, software analytics, DevOps},
    location = {Montreal, Quebec, Canada},
    series = {ICSE '19}
}

@inproceedings{mlops-ossara,
    author = {Moreschini, Sergio and H\"{a}stbacka, David and Taibi, Davide},
    title = {MLOps Pipeline Development: The OSSARA Use Case},
    year = {2023},
    isbn = {9798400702280},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi-org.proxy2.library.illinois.edu/10.1145/3599957.3606211},
    doi = {10.1145/3599957.3606211},
    abstract = {Software development based on MLOps practices is entering its early adoption stage. As for it, practitioners and researchers are starting to develop pipelines composed of tools capable of automating the whole software lifecycle. The development of the pipeline however is not as straightforward as it looks and some key points need to be addressed. In this work, we propose our vision for the development of the MLOps pipeline by showing what to keep into account when choosing the tools for each step of a pipeline. The proposition has been backed up by describing a developed use case scenario: the OSSARA use case. We believe that the presented use case, as well as the remarks presented for the process of tool selection for each MLOps phase, will help practitioners and researchers in the process of developing their own pipelines.},
    booktitle = {Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems},
    articleno = {31},
    numpages = {8},
    keywords = {MLOps, Machine Learning, pipelines},
    location = {Gdansk, Poland},
    series = {RACS '23}
}

@article{aiops-node-failures-alibaba,
    author = {Li, Yangguang and Jiang, Zhen Ming (Jack) and Li, Heng and Hassan, Ahmed E. and He, Cheng and Huang, Ruirui and Zeng, Zhengda and Wang, Mian and Chen, Pinan},
    title = {Predicting Node Failures in an Ultra-Large-Scale Cloud Computing Platform: An AIOps Solution},
    year = {2020},
    issue_date = {April 2020},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {29},
    number = {2},
    issn = {1049-331X},
    url = {https://doi-org.proxy2.library.illinois.edu/10.1145/3385187},
    doi = {10.1145/3385187},
    abstract = {Many software services today are hosted on cloud computing platforms, such as Amazon EC2, due to many benefits like reduced operational costs. However, node failures in these platforms can impact the availability of their hosted services and potentially lead to large financial losses. Predicting node failures before they actually occur is crucial, as it enables DevOps engineers to minimize their impact by performing preventative actions. However, such predictions are hard due to many challenges like the enormous size of the monitoring data and the complexity of the failure symptoms. AIOps (Artificial Intelligence for IT Operations), a recently introduced approach in DevOps, leverages data analytics and machine learning to improve the quality of computing platforms in a cost-effective manner. However, the successful adoption of such AIOps solutions requires much more than a top-performing machine learning model. Instead, AIOps solutions must be trustable, interpretable, maintainable, scalable, and evaluated in context. To cope with these challenges, in this article we report our process of building an AIOps solution for predicting node failures for an ultra-large-scale cloud computing platform at Alibaba. We expect our experiences to be of value to researchers and practitioners, who are interested in building and maintaining AIOps solutions for large-scale cloud computing platforms.},
    journal = {ACM Trans. Softw. Eng. Methodol.},
    month = {apr},
    articleno = {13},
    numpages = {24},
    keywords = {AIOps, ultra-large-scale platforms, cloud computing, failure prediction}
}

// Jason's papers

@inproceedings{source-code-understanding,
    author = {Suneja, Sahil and Zheng, Yunhui and Zhuang, Yufan and Laredo, Jim A. and Morari, Alessandro},
    title = {Towards Reliable AI for Source Code Understanding},
    year = {2021},
    isbn = {9781450386388},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi-org.proxy2.library.illinois.edu/10.1145/3472883.3486995},
    doi = {10.1145/3472883.3486995},
    abstract = {Cloud maturity and popularity have resulted in Open source software (OSS) proliferation. And, in turn, managing OSS code quality has become critical in ensuring sustainable Cloud growth. On this front, AI modeling has gained popularity in source code understanding tasks, promoted by the ready availability of large open codebases. However, we have been observing certain peculiarities with these black-boxes, motivating a call for their reliability to be verified before offsetting traditional code analysis. In this work, we highlight and organize different reliability issues affecting AI-for-code into three stages of an AI pipeline- data collection, model training, and prediction analysis. We highlight the need for concerted efforts from the research community to ensure credibility, accountability, and traceability for AI-for-code. For each stage, we discuss unique opportunities afforded by the source code and software engineering setting to improve AI reliability.},
    booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
    pages = {403–411},
    numpages = {9},
    keywords = {explainability, machine learning, signal awareness, reliability},
    location = {Seattle, WA, USA},
    series = {SoCC '21}
}

@inproceedings{network-log-anomaly-detection,
    author = {Ohana, David and Wassermann, Bruno and Dupuis, Nicolas and Kolodner, Elliot and Raichstein, Eran and Malka, Michal},
    title = {Hybrid Anomaly Detection and Prioritization for Network Logs at Cloud Scale},
    year = {2022},
    isbn = {9781450391627},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi-org.proxy2.library.illinois.edu/10.1145/3492321.3519566},
    doi = {10.1145/3492321.3519566},
    abstract = {Monitoring the health of large-scale systems requires significant manual effort, usually through the continuous curation of alerting rules based on keywords, thresholds and regular expressions, which might generate a flood of mostly irrelevant alerts and obscure the actual information operators would like to see. Existing approaches try to improve the observability of systems by intelligently detecting anomalous situations. Such solutions surface anomalies that are statistically significant, but may not represent events that reliability engineers consider relevant. We propose ADEPTUS, a practical approach for detection of relevant health issues in an established system. ADEPTUS combines statistics and unsupervised learning to detect anomalies with supervised learning and heuristics to determine which of the detected anomalies are likely to be relevant to the Site Reliability Engineers (SREs). ADEPTUS overcomes the labor-intensive prerequisite of obtaining anomaly labels for supervised learning by automatically extracting information from historic alerts and incident tickets. We leverage ADEPTUS for observability in the network infrastructure of IBM Cloud. We perform an extensive real-world evaluation on 10 months of logs generated by tens of thousands of network devices across 11 data centers and demonstrate that ADEPTUS achieves higher alerting accuracy than the rule-based log alerting solution, curated by domain experts, used by SREs daily.},
    booktitle = {Proceedings of the Seventeenth European Conference on Computer Systems},
    pages = {236–250},
    numpages = {15},
    keywords = {deep learning, reliability, cloud computing, machine learning, anomaly detection, log analysis, AIOps},
    location = {Rennes, France},
    series = {EuroSys '22}
}

@inproceedings{model-checking-guided-testing,
    author = {Wang, Dong and Dou, Wensheng and Gao, Yu and Wu, Chenao and Wei, Jun and Huang, Tao},
    title = {Model Checking Guided Testing for Distributed Systems},
    year = {2023},
    isbn = {9781450394871},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi-org.proxy2.library.illinois.edu/10.1145/3552326.3587442},
    doi = {10.1145/3552326.3587442},
    abstract = {Distributed systems have become the backbone of cloud computing. Incorrect system designs and implementations can greatly impair the reliability of distributed systems. Although a distributed system design modelled in the formal specification can be verified by formal model checking, it is still challenging to figure out whether its corresponding implementation conforms to the verified specification. An incorrect system implementation can violate its verified specification, and causes intricate bugs.In this paper, we propose a novel distributed system testing technique, Model checking guided testing (Mocket), to fill the gap between the specification and its implementation in a distributed system. Specially, we use the state space generated by formal model checking to guide the testing for the system implementation, and unearth bugs in the target distributed system. To evaluate the feasibility and effectiveness of Mocket, we apply Mocket on three popular distributed systems, and find 3 previously unknown bugs in them.},
    booktitle = {Proceedings of the Eighteenth European Conference on Computer Systems},
    pages = {127–143},
    numpages = {17},
    keywords = {distributed system, testing, model checking},
    location = {Rome, Italy},
    series = {EuroSys '23}
}